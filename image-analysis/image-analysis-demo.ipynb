{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analyze images with Azure Computer Vision"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Computer Vision is a cognitive service in Microsoft Azure and provides pre-built, advanced algorithms that process and analyze images.\r\n",
    "\r\n",
    "In this article, we will explore the pre-trained models of Azure Computer Vision service for image analysis.\r\n",
    "\r\n",
    "You will learn how to:\r\n",
    "* Provision a Computer Vision resource.\r\n",
    "* Use a Computer Vision resource to analyze an image."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a Computer Vision Resource"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Sign in to [Azure Portal](https://portal.azure.com/) and select **Create a resource**.\r\n",
    "2. Search for **Computer Vision** and then click **Create**.\r\n",
    "3. Create a Computer Vision resource with the following settings:\r\n",
    "    * **Subscription**: Your Azure subscription.\r\n",
    "    * **Resource group**: Select an existing resource group or create a new one.\r\n",
    "    * **Region**: Choose any available region, for example **North Europe**.\r\n",
    "    * **Name**: This would be your custom domain name in your endpoint. Enter a unique name.\r\n",
    "    * **Pricing tier**: You can use the free pricing tier (**F0**) to try the service, and upgrade later to a paid tier.\r\n",
    "4. Select **Review + Create** and wait for deployment to complete.\r\n",
    "5. One the deployment is complete, select **Go to resource**. On the **Overview** tab, click **Manage keys**. Save the **Key 1** and the **Endpoint**. You will need the key and the endpoint to connect to your Computer Vision resource from client applications.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\r\n",
    "from msrest.authentication import CognitiveServicesCredentials\r\n",
    "from PIL import Image\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.patches as patches"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create variables for your key and endpoint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "key = 'YOUR_KEY'\r\n",
    "endpoint = 'YOUR_ENDPOINT'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Authenticate the client"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(key))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyze images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First download the images used in the following examples from my [GitHub repository](https://github.com/sfoteini/azure-computer-vision)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate image description"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Open local image file\r\n",
    "image_path = \"images/city2.jpg\"\r\n",
    "image = open(image_path, \"rb\")\r\n",
    "\r\n",
    "# Display the image\r\n",
    "display(Image.open(image_path).resize((412, 250)))\r\n",
    "\r\n",
    "# Call the API\r\n",
    "description_result = computervision_client.describe_image_in_stream(image)\r\n",
    "\r\n",
    "# Get the description with confidence level\r\n",
    "print(\"Description:\")\r\n",
    "if (len(description_result.captions) == 0):\r\n",
    "    print(\"No description detected.\")\r\n",
    "else:\r\n",
    "    for caption in description_result.captions:\r\n",
    "        print(f\"{caption.text} with confidence {caption.confidence * 100:.2f}%\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try another image."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Open local image file\r\n",
    "image_path = \"images/cows.jpg\"\r\n",
    "image = open(image_path, \"rb\")\r\n",
    "\r\n",
    "# Display the image\r\n",
    "display(Image.open(image_path).resize((334, 250)))\r\n",
    "\r\n",
    "# Call the API\r\n",
    "description_result = computervision_client.describe_image_in_stream(image)\r\n",
    "\r\n",
    "# Get the description with confidence level\r\n",
    "print(\"Description:\")\r\n",
    "if (len(description_result.captions) == 0):\r\n",
    "    print(\"No description detected.\")\r\n",
    "else:\r\n",
    "    for caption in description_result.captions:\r\n",
    "        print(f\"{caption.text} with confidence {caption.confidence * 100:.2f}%\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tag visual features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Open local image file\r\n",
    "image_path = \"images/golf.jpg\"\r\n",
    "image = open(image_path, \"rb\")\r\n",
    "\r\n",
    "# Display the image\r\n",
    "display(Image.open(image_path).resize((375, 250)))\r\n",
    "\r\n",
    "# Call the API\r\n",
    "tags_result = computervision_client.tag_image_in_stream(image)\r\n",
    "\r\n",
    "# Get the tags with confidence level\r\n",
    "print(\"Tags:\")\r\n",
    "if (len(tags_result.tags) == 0):\r\n",
    "    print(\"No tags detected.\")\r\n",
    "else:\r\n",
    "    for tag in tags_result.tags:\r\n",
    "        print(f\"{tag.name}: {tag.confidence * 100:.2f}%\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Categorize an image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Open local image file\r\n",
    "image_path = \"images/empirestatebuilding.jpg\"\r\n",
    "image = open(image_path, \"rb\")\r\n",
    "\r\n",
    "# Display the image\r\n",
    "display(Image.open(image_path).resize((377, 250)))\r\n",
    "\r\n",
    "# Call the API\r\n",
    "# By default, image categories are returned.\r\n",
    "categorize_result = computervision_client.analyze_image_in_stream(image)\r\n",
    "\r\n",
    "# Get the categories with confidence score\r\n",
    "print(\"Categories:\")\r\n",
    "if (len(categorize_result.categories) == 0):\r\n",
    "    print(\"No categories detected.\")\r\n",
    "else:\r\n",
    "    for category in categorize_result.categories:\r\n",
    "        print(f\"{category.name}: {category.score * 100:.2f}%\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Detect faces"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Open local image file\r\n",
    "image_path = \"images/peopleworking1.jpg\"\r\n",
    "image = open(image_path, \"rb\")\r\n",
    "\r\n",
    "img = Image.open(image_path)\r\n",
    "\r\n",
    "# Select visual features you want\r\n",
    "img_features = [\"faces\"]\r\n",
    "\r\n",
    "# Call the API\r\n",
    "faces_result = computervision_client.analyze_image_in_stream(image, img_features)\r\n",
    "\r\n",
    "# Print the results\r\n",
    "\r\n",
    "# Create figure and axes\r\n",
    "fig, ax = plt.subplots()\r\n",
    "\r\n",
    "# Display the image\r\n",
    "ax.imshow(img)\r\n",
    "\r\n",
    "print(\"Faces:\")\r\n",
    "if (len(faces_result.faces) == 0):\r\n",
    "    print(\"No faces detected.\")\r\n",
    "else:\r\n",
    "    for face in faces_result.faces:\r\n",
    "        # Create a Rectangle patch\r\n",
    "        rect = patches.Rectangle((face.face_rectangle.left, face.face_rectangle.top), face.face_rectangle.width, face.face_rectangle.height, linewidth=2, edgecolor='r', facecolor='none')\r\n",
    "\r\n",
    "        # Add the patch to the Axes\r\n",
    "        ax.add_patch(rect)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Detect objects"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get local image\r\n",
    "image_path = \"images/cats.jpg\"\r\n",
    "image = open(image_path, \"rb\")\r\n",
    "\r\n",
    "img = Image.open(image_path)\r\n",
    "\r\n",
    "# Call API with local image\r\n",
    "detect_objects_results = computervision_client.detect_objects_in_stream(image)\r\n",
    "\r\n",
    "# Print results of detection with bounding boxes\r\n",
    "\r\n",
    "# Create figure and axes\r\n",
    "fig, ax = plt.subplots()\r\n",
    "\r\n",
    "# Display the image\r\n",
    "ax.imshow(img)\r\n",
    "\r\n",
    "print(\"Objects in image:\")\r\n",
    "if len(detect_objects_results.objects) == 0:\r\n",
    "    print(\"No objects detected.\")\r\n",
    "else:\r\n",
    "    for object in detect_objects_results.objects:\r\n",
    "        # Create a Rectangle patch\r\n",
    "        rect = patches.Rectangle((object.rectangle.x, object.rectangle.y), object.rectangle.w, object.rectangle.h, linewidth=2, edgecolor='r', facecolor='none')\r\n",
    "\r\n",
    "        # Add the patch to the Axes\r\n",
    "        ax.add_patch(rect)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "2deb099b60a8b4da913787c955f1d57026f67c6109413fa49af9a1fc936f94ce"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}